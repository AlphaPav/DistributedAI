{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning\n",
    "## 概念\n",
    "    传统机器学习方法，需要把训练数据集中于某一台机器或是单个数据中心里。谷歌建设了规模庞大的云计算基础设施，来对数据进行处理。现在，为利用移动设备上的人机交互来训练模型，谷歌发明了一个新名词——Federated Learning。\n",
    "\n",
    "> 那么，什么是 Federated Learning？\n",
    "\n",
    "    它意为“联合学习”——能使多台智能手机以协作的形式，学习共享的预测模型。与此同时，所有的训练数据保存在终端设备。这意味着在 Federated Learning 的方式下，把数据保存在云端，不再是搞大规模机器学习的必要前提。\n",
    "\n",
    "> 最重要的一点：Federated Learning 并不仅仅是在智能手机上运行本地模型做预测 （比如 Mobile Vision API 和 On-Device Smart Reply），而更进一步，让移动设备能够协同进行模型训练。\n",
    "\n",
    "## 工作原理\n",
    "    Federated Learning 的工作方式如下：\n",
    "\n",
    "1. 智能手机下载当前版本的模型\n",
    "2. 通过学习本地数据来改进模型\n",
    "3. 把对模型的改进，概括成一个比较小的专门更新\n",
    "4. 该模型的更新被**加密**发送到云端\n",
    "5. 与其他用户的更新即时整合，平均，作为对共享模型的改进\n",
    "6. 所有的训练数据仍然在每名终端用户的设备中，个人更新不会在云端保存。\n",
    "\n",
    "如图下：\n",
    "![](http://bp.googleblog.cn/-K65Ed68KGXk/WOa9jaRWC6I/AAAAAAAABsM/gglycD_anuQSp-i67fxER1FOlVTulvV2gCLcB/s1600/FederatedLearning_FinalFiles_Flow%2BChart1.png)\n",
    "\n",
    "整个过程有三个关键环节：\n",
    "\n",
    "- 根据用户使用情况，每台手机在本地对模型进行个性化改进\n",
    "- 形成一个整体的模型修改方案\n",
    "- 应用于共享的模型\n",
    "该过程会不断循环。\n",
    "\n",
    "Federated Learning 的主要优点有：\n",
    "\n",
    "- 更智能的模型\n",
    "- 低延迟\n",
    "- 低功耗\n",
    "- 保障用户隐私\n",
    "另外，在向共享模型提供更新之外；本地的改进模型可以即时使用，这能向用户提供**个性化的使用体验**。\n",
    "## 案例：谷歌输入法\n",
    "    目前，谷歌正在谷歌输入法 Gboard 上测试 Federated Learning。当 Gboard 显示推荐搜索项，不论用户是否最终点击了推荐项，智能手机会在本地存储相关信息。Federated Learning 会对设备历史数据进行处理，然后对 Gboard 检索推荐模型提出改进。这个与推荐算法很像，但模型更新先在本地发生，再到云端整合。\n",
    "## 技术挑战与解决方案\n",
    "\n",
    "### 算法与技术上的挑战\n",
    "    在典型的机器学习系统中，超大型数据集会被平均分割到云端的多个服务器上，像随机梯度下降（SGD）这样的优化算法便运行于其上。这类反复迭代的算法，与训练数据之间需要低延迟、高吞吐量的连接。而在 Federated Learning 的情况下，数据以非常不平均的方式分布在数百万的移动设备上。相比之下，智能手机的延迟更高、网络吞吐量更低，并且仅可在保证用户日常使用的前提下，断断续续地进行训练。\n",
    "\n",
    "### 解决方案  \n",
    "- 为解决这些带宽、延迟问题，谷歌开发出一套名为 Federated Averaging 的算法。相比原生的 Federated Learning 版本随机梯度下降，该算法对训练深度神经网络的通讯要求，要低 10 到 100 倍。该算法的核心思路，是利用智能移动设备的强大处理器来计算出更高质量的更新，而不仅仅是优化。做一个好模型，高质量的更新会意味着迭代次数的减少。因此，模型训练能够减少通讯需求。\n",
    "- 减少上行次数，由于上行速度一般比下行速度慢很多，谷歌开发了一种比较新奇的方式，将上行通讯需求再次减少的 100 倍之多：使用随机 rotation 和 quantization 来压缩更新。虽然这些解决方案聚焦于训练深度网络，谷歌还设计了一个针对高维稀疏 convex 模型的算法，特别擅长点击率预测等问题。\n",
    "- 在数百万不同的智能手机上部署 Federated Learning，需要非常复杂的技术整合，设备本地的模型训练，使用的是迷你版的 TensorFlow。非常细致的 scheduling 系统，保证只有用户手机闲置、插着电、有 Wi-Fi 时才训练模型。所以在智能手机的日常使用中，Federated Learning 并不会影响性能\n",
    "- Federated learning 不需要在云端存储用户数据。但为避免用户隐私泄露，开发了一个名为 Secure Aggregation、使用加密技术的协议。由于此草案，系统服务器只能够解码至少 100 或 1000 名用户参与的平均更新。在整合以前，用户的个体更新不能被查看。\n",
    "- 此类协议，对于深度网络层级的问题以及现实通讯瓶颈具有使用价值。谷歌表示，设计 Federated Averaging，是为了让服务器只需要整合后的更新，让 Secure Aggregation 能够派上用场。\n",
    "\n",
    "## 小结\n",
    "- 谷歌表示，Federated learning 的潜力十分巨大，现在只不过探索了它的皮毛。但它无法用来处理所有的机器学习问题。对于许多其他模型，必需的训练数据已经存在云端 （比如训练 Gmail 的垃圾邮件过滤器）。因此，谷歌表示会继续探索基于云计算的 ML，但同时“下定决心”不断拓展 Federated Learning 的功能。\n",
    "- 对 Federated Learning 进行应用，需要机器学习开发者采用新的开发工具以及全新思路——从模型开发、训练一直到模型评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
