{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magic:2051, count: 60000, size: 28*28\n",
      "done 10000pictures\n",
      "done 20000pictures\n",
      "done 30000pictures\n",
      "done 40000pictures\n",
      "done 50000pictures\n",
      "done 60000pictures\n",
      "magic:2049, num_images: 60000 pairs\n",
      "done 10000pairs\n",
      "done 20000pairs\n",
      "done 30000pairs\n",
      "done 40000pairs\n",
      "done 50000pairs\n",
      "done 60000pairs\n",
      "magic:2051, count: 10000, size: 28*28\n",
      "done 10000pictures\n",
      "magic:2049, num_images: 10000 pairs\n",
      "done 10000pairs\n",
      "cost after iteration 0:\n",
      "[[-0.62811176]]\n",
      "cost after iteration 1000:\n",
      "[[-0.25876455]]\n",
      "cost after iteration 2000:\n",
      "[[-0.34338076]]\n",
      "cost after iteration 3000:\n",
      "[[-0.36470343]]\n",
      "cost after iteration 4000:\n",
      "[[-0.13882801]]\n",
      "cost after iteration 5000:\n",
      "[[-0.1216571]]\n",
      "cost after iteration 6000:\n",
      "[[-0.09286688]]\n",
      "cost after iteration 7000:\n",
      "[[-0.26100521]]\n",
      "cost after iteration 8000:\n",
      "[[-0.06171823]]\n",
      "cost after iteration 9000:\n",
      "[[-0.13944045]]\n",
      "cost after iteration 10000:\n",
      "[[-0.04790998]]\n",
      "cost after iteration 11000:\n",
      "[[-0.05128911]]\n",
      "cost after iteration 12000:\n",
      "[[-0.09299672]]\n",
      "cost after iteration 13000:\n",
      "[[-0.10173517]]\n",
      "cost after iteration 14000:\n",
      "[[-0.05028028]]\n",
      "cost after iteration 15000:\n",
      "[[-0.16211468]]\n",
      "cost after iteration 16000:\n",
      "[[-0.03805916]]\n",
      "cost after iteration 17000:\n",
      "[[-0.08200182]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2b3215cb6698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mimgvector1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage2vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mimgvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnarmalize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgvector1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mpre_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2b3215cb6698>\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(X, parameters)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "#_*_ coding:utf-8 _*_\n",
    "\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "# 读取文件\n",
    "train_images_idx3_ubyte_file = './MNIST/train-images-idx3-ubyte'\n",
    "train_labels_idx1_ubyte_file = './MNIST/train-labels-idx1-ubyte'\n",
    "\n",
    "test_images_idx3_ubyte_file = './MNIST/t10k-images-idx3-ubyte'\n",
    "test_labels_idx1_ubyte_file = './MNIST/t10k-labels-idx1-ubyte'\n",
    "\n",
    "# 数据集里的图片是二进制的,转化成numpy需要的数据形式\n",
    "def decode_idx3_ubyte(idx3_ubyte_file):\n",
    "    bin_data = open(idx3_ubyte_file, 'rb').read()   # 数据集里的图片是二进制\n",
    "\n",
    "    offset = 0\n",
    "    fmt_header = '>IIII'    # f='>IIII'是二进制大端读取方法\n",
    "    # 文件协议的描述\n",
    "    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    print(\"magic:%d, count: %d, size: %d*%d\" % (magic_number, num_images, num_rows, num_cols))\n",
    "\n",
    "    image_size = num_rows * num_cols\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>' + str(image_size) + 'B'\n",
    "    images = np.empty((num_images, num_rows, num_cols))\n",
    "    for i in range(num_images):\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(\"done %d\" % (i + 1) + \"pictures\")\n",
    "        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return images\n",
    "\n",
    "# 标签 从二进制转换成numpy所需的形式\n",
    "def decode_idx1_ubyte(idx1_ubyte_file):\n",
    "    bin_data = open(idx1_ubyte_file, 'rb').read()\n",
    "\n",
    "    offset = 0\n",
    "    fmt_header = '>ii'\n",
    "    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    print(\"magic:%d, num_images: %d pairs\" % (magic_number, num_images))\n",
    "\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>B'\n",
    "    labels = np.empty(num_images)\n",
    "    for i in range(num_images):\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(\"done %d\" % (i + 1) + \"pairs\")\n",
    "        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return labels\n",
    "\n",
    "# 载入数据\n",
    "def load_train_images(idx_ubyte_file=train_images_idx3_ubyte_file):\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\n",
    "\n",
    "def load_train_labels(idx_ubyte_file=train_labels_idx1_ubyte_file):\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)\n",
    "\n",
    "def load_test_images(idx_ubyte_file=test_images_idx3_ubyte_file):\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\n",
    "\n",
    "def load_test_labels(idx_ubyte_file=test_labels_idx1_ubyte_file):\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)\n",
    "\n",
    "# 标准正则化。以及初始化参数。这里用的是均值初始化。\n",
    "def narmalize_data(ima):\n",
    "    a_max = np.max(ima)\n",
    "    a_min = np.min(ima)\n",
    "    for j in range(ima.shape[0]):\n",
    "        ima[j] = (ima[j] - a_min) / (a_max - a_min)\n",
    "    return ima\n",
    "\n",
    "def initialize_with_zeros(n_x, n_h, n_y):\n",
    "    np.random.seed(2)\n",
    "    W1 = np.random.uniform(-np.sqrt(6) / np.sqrt(n_x + n_h), np.sqrt(6) / np.sqrt(n_h + n_x), size=(n_h, n_x))\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.uniform(-np.sqrt(6) / np.sqrt(n_y + n_h), np.sqrt(6) / np.sqrt(n_y + n_h), size=(n_y, n_h))\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "\n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y, n_h))\n",
    "    assert (b2.shape == (n_y, 1))\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "\n",
    "    return parameters\n",
    "\n",
    "# 前向传播和损失函数的计算\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    return A2, cache\n",
    "\n",
    "\n",
    "def costloss(A2, Y, parameters):\n",
    "    t = 0.00000000001\n",
    "    logprobs = np.multiply(np.log(A2 + t), Y) + np.multiply(np.log(1 - A2 + t), (1 - Y))\n",
    "\n",
    "    cost = np.sum(logprobs, axis=0, keepdims=True) / A2.shape[0]\n",
    "    return cost\n",
    "\n",
    "# 反向传播和更新参数\n",
    "def back_propagation(parameters, cache, X, Y):\n",
    "\n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    Z1 = cache[\"Z1\"]\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(dZ2, A1.T)\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))\n",
    "    dW1 = np.dot(dZ1, X.T)\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True)\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    return grads\n",
    "\n",
    "\n",
    "def update_para(parameters, grads, learning_rate):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    return parameters\n",
    "\n",
    "# 定义sigmoid激活函数，softmax等参数。image2vector的作用是将输入从28*28的图片变成一个列向量。\n",
    "def sigmoid(x):\n",
    "    s=1/(1+np.exp(-x))\n",
    "    return s\n",
    "def image2vector(image):\n",
    "    v=np.reshape(image,[784,1])\n",
    "    return v\n",
    "def softmax(x):\n",
    "    v=np.argmax(x)\n",
    "    return v\n",
    "\n",
    "# n_x为输入图片的大小，本次为28*28。n_h为神经网络的层数。本次实验设计的是两层的神经网络。一个中间层，一个输出层。（输入层不算入层数）。\n",
    "# 本次试验中，中间层是32个神经元，选别的数量也行。此时正确识别数量为9119个。若选为10个神经元，实验得到正确识别结果为8619.可见准确率下降了。\n",
    "# n_y是输出神经元的数量。本次因为是从0-9共10个数字，所以n_y=10。ii是测试集中正确识别了的图片数。\n",
    "# 然后开始训练，循环。直至结束。\n",
    "if __name__ == '__main__':\n",
    "    train_images = load_train_images()\n",
    "    train_labels = load_train_labels()\n",
    "    test_images = load_test_images()\n",
    "    test_labels = load_test_labels()\n",
    "\n",
    "    ii = 0\n",
    "    n_x = 28 * 28\n",
    "    n_h = 32\n",
    "    n_y = 10\n",
    "    parameters = initialize_with_zeros(n_x, n_h, n_y)\n",
    "    train_step = 50000\n",
    "    # train_step = 2000\n",
    "    for i in range(train_step):\n",
    "        img_train = train_images[i]\n",
    "        label_train1 = train_labels[i]\n",
    "        label_train = np.zeros((10, 1))\n",
    "        ttt = 0.001\n",
    "        if i > 1000:\n",
    "            ttt = ttt * 0.999\n",
    "        label_train[int(train_labels[i])] = 1\n",
    "        imgvector1 = image2vector(img_train)\n",
    "        imgvector = narmalize_data(imgvector1)\n",
    "        A2, cache = forward_propagation(imgvector, parameters)\n",
    "        pre_label = softmax(A2)\n",
    "\n",
    "        costl = costloss(A2, label_train, parameters)\n",
    "        grads = back_propagation(parameters, cache, imgvector, label_train)\n",
    "        parameters = update_para(parameters, grads, learning_rate=ttt)\n",
    "        grads[\"dW1\"] = 0\n",
    "        grads[\"dW2\"] = 0\n",
    "        grads[\"db1\"] = 0\n",
    "        grads[\"db2\"] = 0\n",
    "        if i%1000 == 0:\n",
    "            print(\"cost after iteration %i:\" % (i))\n",
    "            print(costl)\n",
    "    test_steps = 10000\n",
    "    for i in range(test_steps):\n",
    "        img_train = test_images[i]\n",
    "        vector_image = narmalize_data(image2vector(img_train))\n",
    "        label_trainx = test_labels[i]\n",
    "        aa2, xxx = forward_propagation(vector_image, parameters)\n",
    "        predict_value = softmax(aa2)\n",
    "        if predict_value == int(label_trainx):\n",
    "            ii = ii + 1\n",
    "        if i%1000:\n",
    "            print(\"test %d steps\" % i)\n",
    "    print(np.float32(ii/test_steps))    # 识别率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
