# 分布式机器学习时代
## 概念
传统机器学习方法，需要把训练数据集中于某一台机器或是单个数据中心里。谷歌等云服务巨头还建设了规模庞大的云计算基础设施，来对数据进行处理。现在，为利用移动设备上的人机交互来训练模型，谷歌发明了一个新名词——Federated Learning。

> 那么，什么是 Federated Learning？

它意为“联合学习”——能使多台智能手机以协作的形式，学习共享的预测模型。与此同时，所有的训练数据保存在终端设备。这意味着在 Federated Learning 的方式下，把数据保存在云端，不再是搞大规模机器学习的必要前提。

> 最重要的一点：Federated Learning 并不仅仅是在智能手机上运行本地模型做预测 （比如 Mobile Vision API 和 On-Device Smart Reply），而更进一步，让移动设备能够协同进行模型训练。

## 工作原理
Federated Learning 的工作方式如下：

1. 智能手机下载当前版本的模型
2. 通过学习本地数据来改进模型
3. 把对模型的改进，概括成一个比较小的专门更新
4. 该更新被加密发送到云端
5. 与其他用户的更新即时整合，作为对共享模型的改进
6. 所有的训练数据仍然在每名终端用户的设备中，个人更新不会在云端保存。

整个过程有三个关键环节：

- 根据用户使用情况，每台手机在本地对模型进行个性化改进
- 形成一个整体的模型修改方案

- 应用于共享的模型
该过程会不断循环。

谷歌表示，Federated Learning 的主要优点有：

- 更智能的模型
- 低延迟
- 低功耗
- 保障用户隐私
另外，在向共享模型提供更新之外；本地的改进模型可以即时使用，这能向用户提供个性化的使用体验。
## 技术挑战与解决方案
- 为解决这些带宽、延迟问题，谷歌开发出一套名为 Federated Averaging 的算法。相比原生的 Federated Learning 版本随机梯度下降，该算法对训练深度神经网络的通讯要求，要低 10 到 100 倍。谷歌的核心思路，是利用智能移动设备的强大处理器来计算出更高质量的更新，而不仅仅是优化。做一个好模型，高质量的更新会意味着迭代次数的减少。因此，模型训练能够减少通讯需求。
- 开发了一个名为 Secure Aggregation、使用加密技术的协议。由于此草案，系统服务器只能够解码至少 100 或 1000 名用户参与的平均更新。在整合以前，用户的个体更新不能被查看。
- 对于深度网络层级的问题以及现实通讯瓶颈具有使用价值。谷歌表示，设计 Federated Averaging，是为了让服务器只需要整合后的更新，让 Secure Aggregation 能够派上用场。

## 小结
- 谷歌表示，Federated learning 的潜力十分巨大，现在只不过探索了它的皮毛。但它无法用来处理所有的机器学习问题。对于许多其他模型，必需的训练数据已经存在云端 （比如训练 Gmail 的垃圾邮件过滤器）。因此，谷歌表示会继续探索基于云计算的 ML，但同时“下定决心”不断拓展 Federated Learning 的功能。
- 对 Federated Learning 进行应用，需要机器学习开发者采用新的开发工具以及全新思路——从模型开发、训练一直到模型评估。

