# Federated Learning
## 概念
    传统机器学习方法，需要把训练数据集中于某一台机器或是单个数据中心里。谷歌建设了规模庞大的云计算基础设施，来对数据进行处理。现在，为利用移动设备上的人机交互来训练模型，谷歌发明了一个新名词——Federated Learning。

> 那么，什么是 Federated Learning？

    它意为“联合学习”——能使多台智能手机以协作的形式，学习共享的预测模型。与此同时，所有的训练数据保存在终端设备。这意味着在 Federated Learning 的方式下，把数据保存在云端，不再是搞大规模机器学习的必要前提。

> 最重要的一点：Federated Learning 并不仅仅是在智能手机上运行本地模型做预测 （比如 Mobile Vision API 和 On-Device Smart Reply），而更进一步，让移动设备能够协同进行模型训练。

## 工作原理
    Federated Learning 的工作方式如下：

1. 智能手机下载当前版本的模型
2. 通过学习本地数据来改进模型
3. 把对模型的改进，概括成一个比较小的专门更新
4. 该模型的更新被**加密**发送到云端
5. 与其他用户的更新即时整合，平均，作为对共享模型的改进
6. 所有的训练数据仍然在每名终端用户的设备中，个人更新不会在云端保存。

如图下：
![](http://bp.googleblog.cn/-K65Ed68KGXk/WOa9jaRWC6I/AAAAAAAABsM/gglycD_anuQSp-i67fxER1FOlVTulvV2gCLcB/s1600/FederatedLearning_FinalFiles_Flow%2BChart1.png)

整个过程有三个关键环节：

- 根据用户使用情况，每台手机在本地对模型进行个性化改进
- 形成一个整体的模型修改方案
- 应用于共享的模型
该过程会不断循环。

Federated Learning 的主要优点有：

- 更智能的模型
- 低延迟
- 低功耗
- 保障用户隐私
另外，在向共享模型提供更新之外；本地的改进模型可以即时使用，这能向用户提供**个性化的使用体验**。
## 案例：谷歌输入法
    目前，谷歌正在谷歌输入法 Gboard 上测试 Federated Learning。当 Gboard 显示推荐搜索项，不论用户是否最终点击了推荐项，智能手机会在本地存储相关信息。Federated Learning 会对设备历史数据进行处理，然后对 Gboard 检索推荐模型提出改进。这个与推荐算法很像，但模型更新先在本地发生，再到云端整合。
## 技术挑战与解决方案

### 算法与技术上的挑战
    在典型的机器学习系统中，超大型数据集会被平均分割到云端的多个服务器上，像随机梯度下降（SGD）这样的优化算法便运行于其上。这类反复迭代的算法，与训练数据之间需要低延迟、高吞吐量的连接。而在 Federated Learning 的情况下，数据以非常不平均的方式分布在数百万的移动设备上。相比之下，智能手机的延迟更高、网络吞吐量更低，并且仅可在保证用户日常使用的前提下，断断续续地进行训练。

### 解决方案  
- 为解决这些带宽、延迟问题，谷歌开发出一套名为 Federated Averaging 的算法。相比原生的 Federated Learning 版本随机梯度下降，该算法对训练深度神经网络的通讯要求，要低 10 到 100 倍。该算法的核心思路，是利用智能移动设备的强大处理器来计算出更高质量的更新，而不仅仅是优化。做一个好模型，高质量的更新会意味着迭代次数的减少。因此，模型训练能够减少通讯需求。
- 减少上行次数，由于上行速度一般比下行速度慢很多，谷歌开发了一种比较新奇的方式，将上行通讯需求再次减少的 100 倍之多：使用随机 rotation 和 quantization 来压缩更新。虽然这些解决方案聚焦于训练深度网络，谷歌还设计了一个针对高维稀疏 convex 模型的算法，特别擅长点击率预测等问题。
- 在数百万不同的智能手机上部署 Federated Learning，需要非常复杂的技术整合，设备本地的模型训练，使用的是迷你版的 TensorFlow。非常细致的 scheduling 系统，保证只有用户手机闲置、插着电、有 Wi-Fi 时才训练模型。所以在智能手机的日常使用中，Federated Learning 并不会影响性能
- Federated learning 不需要在云端存储用户数据。但为避免用户隐私泄露，开发了一个名为 Secure Aggregation、使用加密技术的协议。由于此草案，系统服务器只能够解码至少 100 或 1000 名用户参与的平均更新。在整合以前，用户的个体更新不能被查看。
- 此类协议，对于深度网络层级的问题以及现实通讯瓶颈具有使用价值。谷歌表示，设计 Federated Averaging，是为了让服务器只需要整合后的更新，让 Secure Aggregation 能够派上用场。

## 小结
- 谷歌表示，Federated learning 的潜力十分巨大，现在只不过探索了它的皮毛。但它无法用来处理所有的机器学习问题。对于许多其他模型，必需的训练数据已经存在云端 （比如训练 Gmail 的垃圾邮件过滤器）。因此，谷歌表示会继续探索基于云计算的 ML，但同时“下定决心”不断拓展 Federated Learning 的功能。
- 对 Federated Learning 进行应用，需要机器学习开发者采用新的开发工具以及全新思路——从模型开发、训练一直到模型评估。

